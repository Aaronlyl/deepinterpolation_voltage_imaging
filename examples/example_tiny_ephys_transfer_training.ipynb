{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example_tiny_ephys_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M_eJxepJjMU"
      },
      "source": [
        "We first get necessary external data and code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhfkEfaoA9eT",
        "outputId": "f72d6bd2-e387-41e4-c951-a37a0593e225",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/AllenInstitute/deepinterpolation.git\n",
        "!mkdir -p ephys"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'deepinterpolation' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjcbfWj_Jopq"
      },
      "source": [
        "Install deepinterpolation package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK8RFhYQJoyK",
        "outputId": "2db29cec-384d-421c-966d-e54aa0ffb772",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install git+https://github.com/AllenInstitute/deepinterpolation.git"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/AllenInstitute/deepinterpolation.git\n",
            "  Cloning https://github.com/AllenInstitute/deepinterpolation.git to /private/var/folders/hy/9t9mb1ln50z59qlgy6nc7y7r3s796j/T/pip-req-build-zthhkwzm\n",
            "Requirement already satisfied (use --upgrade to upgrade): deepinterpolation==0.1.0 from git+https://github.com/AllenInstitute/deepinterpolation.git in /Users/jeromel/Documents/Work documents/Allen Institute/Projects/Deep2P/repos/public/deepinterpolation\n",
            "Building wheels for collected packages: deepinterpolation\n",
            "  Building wheel for deepinterpolation (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for deepinterpolation: filename=deepinterpolation-0.1.0-py3-none-any.whl size=21725 sha256=10259817285bfa10cf2d9ab267b92bca6aed56e616fb5a36de6f91afc5e7ac40\n",
            "  Stored in directory: /private/var/folders/hy/9t9mb1ln50z59qlgy6nc7y7r3s796j/T/pip-ephem-wheel-cache-ullpkl4l/wheels/8e/c0/d8/0c84568edf2d461bf07b4e88eacb17b4ca3765e331f319c3b6\n",
            "Successfully built deepinterpolation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8RG4iRoCRUE"
      },
      "source": [
        "import deepinterpolation as de\n",
        "import sys\n",
        "from shutil import copyfile\n",
        "import os\n",
        "from deepinterpolation.generic import JsonSaver, ClassLoader\n",
        "import datetime\n",
        "from typing import Any, Dict\n",
        "import pathlib\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Nogrv6xClZQ"
      },
      "source": [
        "This is used for record-keeping\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwuBrQ_jC6Ya"
      },
      "source": [
        "now = datetime.datetime.now()\n",
        "run_uid = now.strftime(\"%Y_%m_%d_%H_%M\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPO8knNmC62U"
      },
      "source": [
        "Initialize meta-parameters objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HMK5cRDC-gz"
      },
      "source": [
        "training_param = {}\n",
        "generator_param = {}\n",
        "network_param = {}\n",
        "generator_test_param = {}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn7PSaI-C-01"
      },
      "source": [
        "An epoch is defined as the number of batches pulled from the dataset. Because our datasets are VERY large. Often, we cannot\n",
        "go through the entirity of the data so we define an epoch slightly differently than is usual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzKVMosLDCsb"
      },
      "source": [
        "steps_per_epoch = 10"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7s66NK5DCx_"
      },
      "source": [
        "Those are parameters used for the Validation test generator. Here the test is done on the beginning of the data but\n",
        "this can be a separate file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VsVLdJEC-8k"
      },
      "source": [
        "generator_test_param[\"type\"] = \"generator\"  # type of collection\n",
        "generator_test_param[\"name\"] = \"EphysGenerator\"  # Name of object in the collection\n",
        "generator_test_param[\n",
        "    \"pre_post_frame\"\n",
        "] = 30  # Number of frame provided before and after the predicted frame\n",
        "generator_test_param[\"train_path\"] = os.path.join(\n",
        "    \"deepinterpolation\",\n",
        "    \"sample_data\",\n",
        "    \"ephys_tiny_continuous.dat2\",\n",
        ")\n",
        "generator_test_param[\"batch_size\"] = 100\n",
        "generator_test_param[\"start_frame\"] = 0\n",
        "generator_test_param[\"end_frame\"] = 1999\n",
        "generator_test_param[\n",
        "    \"pre_post_omission\"\n",
        "] = 1  # Number of frame omitted before and after the predicted frame\n",
        "generator_test_param[\"steps_per_epoch\"] = steps_per_epoch"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7e0BhTBEH_L"
      },
      "source": [
        "Those are parameters used for the main data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCcCqT_hAuun"
      },
      "source": [
        "generator_param[\"type\"] = \"generator\"\n",
        "generator_param[\"steps_per_epoch\"] = steps_per_epoch\n",
        "generator_param[\"name\"] = \"EphysGenerator\"\n",
        "generator_param[\"pre_post_frame\"] = 30\n",
        "generator_param[\"train_path\"] = os.path.join(\n",
        "    \"deepinterpolation\",\n",
        "    \"sample_data\",\n",
        "    \"ephys_tiny_continuous.dat2\",\n",
        ")\n",
        "generator_param[\"batch_size\"] = 100\n",
        "generator_param[\"start_frame\"] = 2000\n",
        "generator_param[\"end_frame\"] = 7099\n",
        "generator_param[\"pre_post_omission\"] = 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAu-UN8zEjxz"
      },
      "source": [
        "Those are parameters used for the training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjINOf20EkCz"
      },
      "source": [
        "training_param[\"type\"] = \"trainer\"\n",
        "training_param[\"name\"] = \"transfer_trainer\"\n",
        "training_param[\"run_uid\"] = run_uid\n",
        "\n",
        "# Path to model to transfer and fine-tune\n",
        "training_param[\"model_path\"] = \"ephys/unet_single_ephys_1024_mean_absolute_error_2020_11_12_18_34_2020_11_12_18_34/2020_11_12_18_34_unet_single_ephys_1024_mean_absolute_error_2020_11_12_18_34_model.h5\"\n",
        "training_param[\"batch_size\"] = generator_test_param[\"batch_size\"]\n",
        "training_param[\"steps_per_epoch\"] = steps_per_epoch\n",
        "training_param[\n",
        "    \"period_save\"\n",
        "] = 25  # network model is potentially saved during training between a regular nb epochs\n",
        "training_param[\"nb_gpus\"] = 0\n",
        "training_param[\"apply_learning_decay\"] = 0\n",
        "training_param[\n",
        "    \"nb_times_through_data\"\n",
        "] = 1  # if you want to cycle through the entire data. Two many iterations will cause noise overfitting\n",
        "training_param[\"learning_rate\"] = 0.0001\n",
        "training_param[\"pre_post_frame\"] = generator_test_param[\"pre_post_frame\"]\n",
        "training_param[\"loss\"] = \"mean_absolute_error\"\n",
        "training_param[\n",
        "    \"nb_workers\"\n",
        "] = 1  # this is to enable multiple threads for data generator loading. Useful when this is slower than training\n",
        "\n",
        "training_param[\"model_string\"] = (\n",
        "    \"transfer\"\n",
        "    + \"_\"\n",
        "    + training_param[\"loss\"]\n",
        "    + \"_\"\n",
        "    + training_param[\"run_uid\"]\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STXWqSIHEkSr"
      },
      "source": [
        "Where do you store ongoing training progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a_PwgRGEkjx"
      },
      "source": [
        " jobdir = os.path.join(\n",
        "    \"ephys\", training_param[\"model_string\"] + \"_\" + run_uid,\n",
        ")\n",
        "training_param[\"output_dir\"] = jobdir\n",
        "\n",
        "try:\n",
        "    os.mkdir(jobdir)\n",
        "except:\n",
        "    print(\"folder already exists\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtk6kyuYE0qC"
      },
      "source": [
        "Here we create all json files that are fed to the training. This is used for recording purposes as well as input to the training proces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1odplXwE0xe"
      },
      "source": [
        "path_training = os.path.join(jobdir, \"training.json\")\n",
        "json_obj = JsonSaver(training_param)\n",
        "json_obj.save_json(path_training)\n",
        "\n",
        "path_generator = os.path.join(jobdir, \"generator.json\")\n",
        "json_obj = JsonSaver(generator_param)\n",
        "json_obj.save_json(path_generator)\n",
        "\n",
        "path_test_generator = os.path.join(jobdir, \"test_generator.json\")\n",
        "json_obj = JsonSaver(generator_test_param)\n",
        "json_obj.save_json(path_test_generator)\n",
        "\n",
        "path_network = os.path.join(jobdir, \"network.json\")\n",
        "json_obj = JsonSaver(network_param)\n",
        "json_obj.save_json(path_network)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5O5T6EmE7ss"
      },
      "source": [
        "Here we create all objects for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrOO6Pc7E71m",
        "outputId": "44c55219-8b15-43f9-ebdf-23efb0833b3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# We find the generator obj in the collection using the json file\n",
        "generator_obj = ClassLoader(path_generator)\n",
        "generator_test_obj = ClassLoader(path_test_generator)\n",
        "\n",
        "# We find the training obj in the collection using the json file\n",
        "trainer_obj = ClassLoader(path_training)\n",
        "\n",
        "# We build the generators object. This will, among other things, calculate normalizing parameters.\n",
        "train_generator = generator_obj.find_and_build()(path_generator)\n",
        "test_generator = generator_test_obj.find_and_build()(path_test_generator)\n",
        "\n",
        "# We build the training object.\n",
        "training_class = trainer_obj.find_and_build()(train_generator, test_generator, path_training)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpVKYBcsCCuz"
      },
      "source": [
        "Start training. This can take very long time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hw-IUVbAxSw",
        "outputId": "0544b182-caa1-493a-f9e3-c5080375c02d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_class.run()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.3887 - val_loss: 0.3639\n",
            "Epoch 2/5\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.3559 - val_loss: 0.3627\n",
            "Epoch 3/5\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "10/10 [==============================] - 26s 3s/step - loss: 0.3497 - val_loss: 0.3607\n",
            "Epoch 4/5\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.3678 - val_loss: 0.3593\n",
            "Epoch 5/5\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.3724 - val_loss: 0.3565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FedXESQAB7f7"
      },
      "source": [
        "Finalize and save output of the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGgJLL5hA0N8",
        "outputId": "4b571095-942c-4300-8253-e655fedb064a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_class.finalize()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ]
    }
  ]
}