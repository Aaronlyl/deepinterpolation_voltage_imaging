{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllenInstitute/deepinterpolation/blob/master/examples/GoogleColab_example_Ophys__Finetuning_and_Inference_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first install the DeepInterpolation package. This is using a branch that was optimized for Google Colab low memory and uses pre-installed tensorflow version.\n",
        "\n"
      ],
      "metadata": {
        "id": "b8ypNagStXjf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhfkEfaoA9eT",
        "outputId": "2ee72450-9cd2-423e-a22f-fe273aa3b7cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/AllenInstitute/deepinterpolation.git@fix/gpu_memory_threads\n",
            "  Cloning https://github.com/AllenInstitute/deepinterpolation.git (to revision fix/gpu_memory_threads) to /tmp/pip-req-build-em7oh0_5\n",
            "  Running command git clone -q https://github.com/AllenInstitute/deepinterpolation.git /tmp/pip-req-build-em7oh0_5\n",
            "  Running command git checkout -b fix/gpu_memory_threads --track origin/fix/gpu_memory_threads\n",
            "  Switched to a new branch 'fix/gpu_memory_threads'\n",
            "  Branch 'fix/gpu_memory_threads' set up to track remote branch 'fix/gpu_memory_threads' from 'origin'.\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from deepinterpolation==0.1.5) (2.8.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from deepinterpolation==0.1.5) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from deepinterpolation==0.1.5) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepinterpolation==0.1.5) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from deepinterpolation==0.1.5) (2.8.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepinterpolation==0.1.5) (1.4.1)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.7/dist-packages (from deepinterpolation==0.1.5) (2021.11.2)\n",
            "Collecting s3fs\n",
            "  Downloading s3fs-2022.1.0-py3-none-any.whl (25 kB)\n",
            "Collecting argschema==2.0.2\n",
            "  Downloading argschema-2.0.2.tar.gz (24 kB)\n",
            "Collecting mlflow==1.14.1\n",
            "  Downloading mlflow-1.14.1-py3-none-any.whl (14.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.2 MB 7.1 MB/s \n",
            "\u001b[?25hCollecting marshmallow==3.0.0rc6\n",
            "  Downloading marshmallow-3.0.0rc6-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow==1.14.1->deepinterpolation==0.1.5) (1.3.0)\n",
            "Collecting docker>=4.0.0\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 44.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow==1.14.1->deepinterpolation==0.1.5) (1.1.4)\n",
            "Collecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting querystring-parser\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow==1.14.1->deepinterpolation==0.1.5) (0.4)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow==1.14.1->deepinterpolation==0.1.5) (0.4.2)\n",
            "Collecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 45.7 MB/s \n",
            "\u001b[?25hCollecting alembic<=1.4.1\n",
            "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 38.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow==1.14.1->deepinterpolation==0.1.5) (1.4.31)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow==1.14.1->deepinterpolation==0.1.5) (2018.9)\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading prometheus_flask_exporter-0.18.7-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mlflow==1.14.1->deepinterpolation==0.1.5) (3.13)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow==1.14.1->deepinterpolation==0.1.5) (7.1.2)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "  Downloading databricks-cli-0.16.4.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow==1.14.1->deepinterpolation==0.1.5) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from mlflow==1.14.1->deepinterpolation==0.1.5) (3.17.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow==1.14.1->deepinterpolation==0.1.5) (1.3.5)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow==1.14.1->deepinterpolation==0.1.5) (0.8.9)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow==1.14.1->deepinterpolation==0.1.5) (1.15.0)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow==1.14.1->deepinterpolation==0.1.5) (3.10.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow==1.14.1->deepinterpolation==0.1.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow==1.14.1->deepinterpolation==0.1.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow==1.14.1->deepinterpolation==0.1.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow==1.14.1->deepinterpolation==0.1.5) (2021.10.8)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow==1.14.1->deepinterpolation==0.1.5) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow==1.14.1->deepinterpolation==0.1.5) (1.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow==1.14.1->deepinterpolation==0.1.5) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow==1.14.1->deepinterpolation==0.1.5) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow==1.14.1->deepinterpolation==0.1.5) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->mlflow==1.14.1->deepinterpolation==0.1.5) (2.0.1)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn->mlflow==1.14.1->deepinterpolation==0.1.5) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->mlflow==1.14.1->deepinterpolation==0.1.5) (3.7.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->deepinterpolation==0.1.5) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->deepinterpolation==0.1.5) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->deepinterpolation==0.1.5) (1.3.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow==1.14.1->deepinterpolation==0.1.5) (0.13.1)\n",
            "Collecting fsspec==2022.01.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 46.9 MB/s \n",
            "\u001b[?25hCollecting aiohttp<=4\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 33.2 MB/s \n",
            "\u001b[?25hCollecting aiobotocore~=2.1.0\n",
            "  Downloading aiobotocore-2.1.1.tar.gz (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting botocore<1.23.25,>=1.23.24\n",
            "  Downloading botocore-1.23.24-py3-none-any.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 25.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.10.10 in /usr/local/lib/python3.7/dist-packages (from aiobotocore~=2.1.0->s3fs->deepinterpolation==0.1.5) (1.13.3)\n",
            "Collecting aioitertools>=0.5.1\n",
            "  Downloading aioitertools-0.9.0-py3-none-any.whl (22 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 37.7 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<=4->s3fs->deepinterpolation==0.1.5) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<=4->s3fs->deepinterpolation==0.1.5) (2.0.11)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 46.9 MB/s \n",
            "\u001b[?25hCollecting typing-extensions>=3.7.4.3\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 46.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepinterpolation==0.1.5) (1.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepinterpolation==0.1.5) (3.3.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepinterpolation==0.1.5) (13.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepinterpolation==0.1.5) (2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepinterpolation==0.1.5) (1.1.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 43.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepinterpolation==0.1.5) (0.24.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepinterpolation==0.1.5) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepinterpolation==0.1.5) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepinterpolation==0.1.5) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepinterpolation==0.1.5) (1.1.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepinterpolation==0.1.5) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepinterpolation==0.1.5) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepinterpolation==0.1.5) (1.43.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepinterpolation==0.1.5) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->deepinterpolation==0.1.5) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->deepinterpolation==0.1.5) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->deepinterpolation==0.1.5) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->deepinterpolation==0.1.5) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->deepinterpolation==0.1.5) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->deepinterpolation==0.1.5) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->deepinterpolation==0.1.5) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->deepinterpolation==0.1.5) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->deepinterpolation==0.1.5) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->deepinterpolation==0.1.5) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->deepinterpolation==0.1.5) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->deepinterpolation==0.1.5) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->deepinterpolation==0.1.5) (3.2.0)\n",
            "Building wheels for collected packages: deepinterpolation, argschema, alembic, databricks-cli, aiobotocore\n",
            "  Building wheel for deepinterpolation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepinterpolation: filename=deepinterpolation-0.1.5-py3-none-any.whl size=34375 sha256=f224b3f56ba4fbe0bf01f70384577e727bd32ce7c0670d51e7203f59c11e0ba8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-j5wqrw4k/wheels/c6/41/1a/24488a235c4c2b5eec3973b25b675df31c765e43926455142a\n",
            "  Building wheel for argschema (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for argschema: filename=argschema-2.0.2-py2.py3-none-any.whl size=17795 sha256=620299c0ae63d7940cac2666801e89b683454e9f3413a969a289c31d691e6aba\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/97/a8/4dbf0458be0af473d083a6354c0c126490e82447237bb0b907\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158171 sha256=dcadfe494f2b85cbca2b19f86dcbe3cf0293b8b5425e0c165cf81589e8341ef1\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.16.4-py3-none-any.whl size=106877 sha256=a3f5904edacbe10b198124daa1b6f253cf5b50f7d29ecf4e2f76175b9098c019\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/a1/6d/fa1d22ea25ed8593887437fe1c7e00f6ef307fc240ccd4dc5c\n",
            "  Building wheel for aiobotocore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aiobotocore: filename=aiobotocore-2.1.1-py3-none-any.whl size=55483 sha256=3fb4ae701230bc14485282f6325130dda1d992236a92f311b168bbce134cd143\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/fd/d3/e85dd95a98c12426ed6864dc24a408c3ca3253d4387b2f1cce\n",
            "Successfully built deepinterpolation argschema alembic databricks-cli aiobotocore\n",
            "Installing collected packages: urllib3, typing-extensions, multidict, frozenlist, yarl, smmap, jmespath, asynctest, async-timeout, aiosignal, websocket-client, python-editor, Mako, gitdb, botocore, aioitertools, aiohttp, tf-estimator-nightly, querystring-parser, prometheus-flask-exporter, marshmallow, gunicorn, gitpython, fsspec, docker, databricks-cli, alembic, aiobotocore, s3fs, mlflow, argschema, deepinterpolation\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n",
            "Successfully installed Mako-1.1.6 aiobotocore-2.1.1 aiohttp-3.8.1 aioitertools-0.9.0 aiosignal-1.2.0 alembic-1.4.1 argschema-2.0.2 async-timeout-4.0.2 asynctest-0.13.0 botocore-1.23.24 databricks-cli-0.16.4 deepinterpolation-0.1.5 docker-5.0.3 frozenlist-1.3.0 fsspec-2022.1.0 gitdb-4.0.9 gitpython-3.1.26 gunicorn-20.1.0 jmespath-0.10.0 marshmallow-3.0.0rc6 mlflow-1.14.1 multidict-6.0.2 prometheus-flask-exporter-0.18.7 python-editor-1.0.4 querystring-parser-1.2.4 s3fs-2022.1.0 smmap-5.0.0 tf-estimator-nightly-2.8.0.dev2021122109 typing-extensions-4.1.1 urllib3-1.25.11 websocket-client-1.2.3 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 install git+https://github.com/AllenInstitute/deepinterpolation.git@fix/gpu_memory_threads"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We import the package FineTuning and Inference interface and some useful libraries for this notebook"
      ],
      "metadata": {
        "id": "Cj9-_x4puf0D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8RG4iRoCRUE"
      },
      "outputs": [],
      "source": [
        "from deepinterpolation.cli.fine_tuning import FineTuning\n",
        "from deepinterpolation.cli.inference import Inference\n",
        "import os\n",
        "import glob\n",
        "import datetime\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We connect a local folder to a public S3 bucket with the Allen Brain Observatory RAW movies stored as hdf5 files. This is using s3fs, an emulated file system. "
      ],
      "metadata": {
        "id": "sXZPiJXSu45L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPTcHXThQyK6",
        "outputId": "46bafdf5-b7fb-452c-f004-6a951bdcbf01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following NEW packages will be installed:\n",
            "  s3fs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 200 kB of archives.\n",
            "After this operation, 557 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 s3fs amd64 1.82-1 [200 kB]\n",
            "Fetched 200 kB in 1s (299 kB/s)\n",
            "Selecting previously unselected package s3fs.\n",
            "(Reading database ... 155113 files and directories currently installed.)\n",
            "Preparing to unpack .../archives/s3fs_1.82-1_amd64.deb ...\n",
            "Unpacking s3fs (1.82-1) ...\n",
            "Setting up s3fs (1.82-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt install s3fs\n",
        "!mkdir /content/s3  \n",
        "!s3fs allen-brain-observatory /content/s3 -o public_bucket=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the path to a single movie on S3 that we will make a copy locally"
      ],
      "metadata": {
        "id": "gC6VpHExvWKp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B-Rs4YtPA0X"
      },
      "outputs": [],
      "source": [
        "input_movie_path = '/content/s3/visual-coding-2p/ophys_movies/ophys_experiment_501254258.h5'\n",
        "output_movie_path = '/content/ophys_experiment_501254258.h5'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We make a copy of a subset of a movie file so as to fit Google Colab more limited free file storage and provide faster local access. "
      ],
      "metadata": {
        "id": "NwY1bCwSvdtG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d14034MuPENF"
      },
      "outputs": [],
      "source": [
        "with h5py.File(input_movie_path, 'r') as file_handle:\n",
        "  data = file_handle['data'][0:5001,:,:]\n",
        "  with h5py.File(output_movie_path,'w') as file_handle_out:\n",
        "    file_handle_out.create_dataset('data',data=data)\n",
        "  del data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We download a pre-trained, optimized DeepInterpolation model. This is currently less validated than the much larger published model but it has the benefit of working well with Colab and is much smaller. So far our results with it are quite good. "
      ],
      "metadata": {
        "id": "JbFGEKJ_1bJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/2021_07_31_09_49_38_095550_unet_1024_search_mean_squared_error_pre_30_post_30_feat_32_power_1_depth_4_unet_True-0125-0.5732.h5 https://www.dropbox.com/s/ljunvnl6lvmrzy7/2021_07_31_09_49_38_095550_unet_1024_search_mean_squared_error_pre_30_post_30_feat_32_power_1_depth_4_unet_True-0125-0.5732.h5?dl=0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vw7CbWP1ICL",
        "outputId": "e91e32e8-a06f-4ead-8580-b590e1524f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-17 22:44:52--  https://www.dropbox.com/s/ljunvnl6lvmrzy7/2021_07_31_09_49_38_095550_unet_1024_search_mean_squared_error_pre_30_post_30_feat_32_power_1_depth_4_unet_True-0125-0.5732.h5?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ljunvnl6lvmrzy7/2021_07_31_09_49_38_095550_unet_1024_search_mean_squared_error_pre_30_post_30_feat_32_power_1_depth_4_unet_True-0125-0.5732.h5 [following]\n",
            "--2022-02-17 22:44:53--  https://www.dropbox.com/s/raw/ljunvnl6lvmrzy7/2021_07_31_09_49_38_095550_unet_1024_search_mean_squared_error_pre_30_post_30_feat_32_power_1_depth_4_unet_True-0125-0.5732.h5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc5f999eb7b909ff7e6538744465.dl.dropboxusercontent.com/cd/0/inline/Bf4aJQWrDm5lROvvTwhDJtXT9XkHDD5H619DMbzTN9zjZsYCnrBHzlm661W2bpBTgHLOrbh9X_Sc76WnXGm5AI7Dp4-bUrRuMqN1hDo7XRT-KpNYBcdoyDj1tt8ZdNtyFtNz3Nm15BbVR5AXlV79PR-c/file# [following]\n",
            "--2022-02-17 22:44:54--  https://uc5f999eb7b909ff7e6538744465.dl.dropboxusercontent.com/cd/0/inline/Bf4aJQWrDm5lROvvTwhDJtXT9XkHDD5H619DMbzTN9zjZsYCnrBHzlm661W2bpBTgHLOrbh9X_Sc76WnXGm5AI7Dp4-bUrRuMqN1hDo7XRT-KpNYBcdoyDj1tt8ZdNtyFtNz3Nm15BbVR5AXlV79PR-c/file\n",
            "Resolving uc5f999eb7b909ff7e6538744465.dl.dropboxusercontent.com (uc5f999eb7b909ff7e6538744465.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to uc5f999eb7b909ff7e6538744465.dl.dropboxusercontent.com (uc5f999eb7b909ff7e6538744465.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘/content/2021_07_31_09_49_38_095550_unet_1024_search_mean_squared_error_pre_30_post_30_feat_32_power_1_depth_4_unet_True-0125-0.5732.h5’\n",
            "\n",
            "/content/2021_07_31     [ <=>                ]   1.08M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-02-17 22:44:54 (18.1 MB/s) - ‘/content/2021_07_31_09_49_38_095550_unet_1024_search_mean_squared_error_pre_30_post_30_feat_32_power_1_depth_4_unet_True-0125-0.5732.h5’ saved [1131072]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Nogrv6xClZQ"
      },
      "source": [
        "We initialize training objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HMK5cRDC-gz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c34b86eb-7ce7-42e8-b27d-3e1d811d7152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:FineTuning:wrote /content/output_folder/2022_02_17_22_43_training_full_args.json\n",
            "INFO:FineTuning:wrote /content/output_folder/2022_02_17_22_43_finetuning.json\n",
            "INFO:FineTuning:wrote /content/output_folder/2022_02_17_22_43_generator.json\n",
            "INFO:FineTuning:wrote /content/output_folder/2022_02_17_22_43_test_generator.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fine-tuning\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 36s 262ms/step - loss: 0.6266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:FineTuning:created objects for training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "200/200 [==============================] - 163s 716ms/step - loss: 0.6283 - val_loss: 0.6267\n",
            "Epoch 2/2\n",
            "200/200 [==============================] - 165s 790ms/step - loss: 0.6276 - val_loss: 0.6263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:FineTuning:fine tuning job finished - finalizing output model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n",
            "Fine-tuning finished\n"
          ]
        }
      ],
      "source": [
        "# Initialize meta-parameters objects\n",
        "finetuning_params = {}\n",
        "generator_param = {}\n",
        "generator_test_param = {}\n",
        "\n",
        "input_movie_path = '/content/ophys_experiment_501254258.h5'\n",
        "\n",
        "# It is recommended to use 10,000 frames for fine-tuning new files. Here we are limiting computation time for the workshop but this notebook can handle it.\n",
        "nb_frame_training = 500\n",
        "input_model_path = '/content/2021_07_31_09_49_38_095550_unet_1024_search_mean_squared_error_pre_30_post_30_feat_32_power_1_depth_4_unet_True-0125-0.5732.h5'\n",
        "output_dir = '/content/output_folder'\n",
        "\n",
        "# Those are parameters used for the Validation test generator.\n",
        "# Here the test is done on the beginning of the data but\n",
        "# this can be a separate file\n",
        "generator_param[\"name\"] = \"OphysGenerator\"  # Name of object (use SingleTifGenerator for tiff files)\n",
        "generator_param[\"pre_frame\"] = 30\n",
        "generator_param[\"post_frame\"] = 30\n",
        "generator_param[\"data_path\"] = input_movie_path\n",
        "generator_param[\"batch_size\"] = 1 # This is small because Colab GPUs do have very smaller memory. Increase on better cards. \n",
        "generator_param[\"start_frame\"] = 0\n",
        "generator_param[\"end_frame\"] = -1\n",
        "generator_param[\"total_samples\"] = nb_frame_training\n",
        "generator_param[\"pre_post_omission\"] = 0  # Number of frame omitted before and after the predicted frame\n",
        "\n",
        "generator_test_param[\"name\"] = \"OphysGenerator\"  # Name of object (use SingleTifGenerator for single tiff files or MultiContinuousTifGenerator for an ordered serie of Tiffs)\n",
        "generator_test_param[\"pre_frame\"] = 30\n",
        "generator_test_param[\"post_frame\"] = 30\n",
        "generator_test_param[\"data_path\"] = input_movie_path\n",
        "generator_test_param[\"batch_size\"] = 1\n",
        "generator_test_param[\"start_frame\"] = 0\n",
        "generator_test_param[\"end_frame\"] = -1\n",
        "generator_test_param[\"total_samples\"] = 100  # This is use to measure validation loss\n",
        "generator_test_param[\"pre_post_omission\"] = 0  # Number of frame omitted before and after the predicted frame\n",
        "\n",
        "\n",
        "# Those are parameters used for the training process\n",
        "finetuning_params[\"name\"] = \"transfer_trainer\"\n",
        "\n",
        "# Change this path to any model you wish to improve\n",
        "local_path = input_model_path\n",
        "finetuning_params[\"model_source\"] = {\n",
        "  \"local_path\": local_path\n",
        "}\n",
        "\n",
        "# An epoch is defined as the number of batches pulled from the dataset before measuring validation loss.\n",
        "# It is mostly for performance tracking \n",
        "# Because our datasets are VERY large. Often, we cannot\n",
        "# go through the entirety of the data so we define an epoch\n",
        "# slightly differently than is usual.\n",
        "steps_per_epoch = 200\n",
        "finetuning_params[\"steps_per_epoch\"] = steps_per_epoch\n",
        "finetuning_params[\n",
        "\"period_save\"\n",
        "] = 25\n",
        "# network model is potentially saved during training between a regular\n",
        "# nb of epochs. Useful to go back to models during training\n",
        "\n",
        "finetuning_params[\"learning_rate\"] = 0.0001\n",
        "finetuning_params[\"loss\"] = \"mean_squared_error\"\n",
        "finetuning_params[\"output_dir\"] = output_dir\n",
        "\n",
        "# Those are not needed when working with local files so turning off. \n",
        "finetuning_params[\"use_multiprocessing\"] = False\n",
        "finetuning_params[\"caching_validation\"] = False\n",
        "\n",
        "args = {\n",
        "\"finetuning_params\": finetuning_params,\n",
        "\"generator_params\": generator_param,\n",
        "\"test_generator_params\": generator_test_param,\n",
        "\"output_full_args\": True\n",
        "}\n",
        "\n",
        "finetuning_obj = FineTuning(input_data=args, args=[])\n",
        "\n",
        "print(\"Starting fine-tuning\")\n",
        "\n",
        "finetuning_obj.run()\n",
        "\n",
        "print(\"Fine-tuning finished\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzKVMosLDCsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1bfc42-c413-42ea-94ef-2f0bd5fefb05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:randomize should be set to False for inference.                         Overriding the parameter\n",
            "INFO:Inference:wrote /content/output_folder/inference_full_args.json\n",
            "INFO:Inference:wrote /content/output_folder/2022_02_17_22_43_inference.json\n",
            "INFO:Inference:wrote /content/output_folder/2022_02_17_22_43_generator.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing data for inference\n",
            "Starting inference\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Inference:created objects for inference\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference finished\n"
          ]
        }
      ],
      "source": [
        "print(\"Preparing data for inference\")\n",
        "# Initialize meta-parameters objects\n",
        "inference_param = {}\n",
        "\n",
        "# We are reusing the data generator for training here.\n",
        "generator_param[\"start_frame\"] = 0\n",
        "generator_param[\"end_frame\"] = 200\n",
        "\n",
        "\n",
        "# This is the name of the underlying inference class called\n",
        "inference_param[\"name\"] = \"core_inferrence\"\n",
        "\n",
        "# Where the output of the previous training is stored\n",
        "local_path = glob.glob(os.path.join(output_dir, \"*_transfer_model.h5\"))[0]\n",
        "\n",
        "inference_param[\"model_source\"] = {\n",
        "\"local_path\": local_path\n",
        "}\n",
        "\n",
        "base_file = os.path.splitext(os.path.basename(input_movie_path))[0]\n",
        "\n",
        "unique_time = str(datetime.datetime.now()).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
        "\n",
        "# Replace this path to where you want to store your output file\n",
        "inference_param[\n",
        "\"output_file\"\n",
        "] = output_dir+'/'+base_file+'-denoised-on-'+unique_time+'.h5'\n",
        "\n",
        "# This option is to add blank frames at the onset and end of the output\n",
        "# movie if some output frames are missing input frames to go through\n",
        "# the model. This could be present at the start and end of the movie.\n",
        "inference_param[\"output_padding\"] = True\n",
        "\n",
        "# this is an optional parameter to bring back output data to a given\n",
        "# precision. Read the CLI documentation for more details.\n",
        "# this is available through\n",
        "# 'python -m deepinterpolation.cli.inference --help'\n",
        "inference_param[\"output_datatype\"] = 'uint16'\n",
        "\n",
        "args = {\n",
        "\"generator_params\": generator_param,\n",
        "\"inference_params\": inference_param,\n",
        "\"output_full_args\": True\n",
        "}\n",
        "\n",
        "inference_obj = Inference(input_data=args, args=[])\n",
        "\n",
        "print(\"Starting inference\")\n",
        "inference_obj.run()\n",
        "\n",
        "print(\"Inference finished\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "2022-02-17- Example_Ophys_- Finetuning and Inference - Workshop.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}